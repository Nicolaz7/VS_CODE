{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\nicol\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\nicol\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nicol\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (69.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyspark\n",
    "!pip install --upgrade setuptools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('arquivo.csv', \n",
    "                    header=True, # existe cabeçalho no arquivo #\n",
    "           inferSchema=True # spark, defina as colunas #\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(2, vertical=True) # gera um df na vertical e não na horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "                'coluna1', 'coluna2'\n",
    "                ) # selecionar uma visão com apenas x colunas #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(f.col('colunaX') > 1) # selecionar os valores que sejam maior que 1 presentes na colunaX # \n",
    "df = df.filter(f.col('colunaX') >= 1) # \n",
    "\n",
    "df = df.filter(f.col('colunaX') == 'oi') #\n",
    "df = df.filter(f.col('colunaX') == 1) #\n",
    "\n",
    "df = df.filter(f.col('colunaX') < 1) #\n",
    "df = df.filter(f.col('colunaX') <= 1) #\n",
    "\n",
    "df = df.filter(f.col('colunaX') != 1) #\n",
    "\n",
    "df = df.filter(f.col('colunaX') == 1) #\n",
    "\n",
    "df = df.filter((f.col('colunaX') == 1) & (f.col('colunaY') != 'ab')) #\n",
    "df = df.filter((f.col('colunaX') == 1) | (f.col('colunaY') != 'ab')) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() # contar linhas do df #\n",
    "\n",
    "df.distinct().count() # contar linhas unicas do df # \n",
    "\n",
    "df.select('coluna').distinct().count() # contar linhas unicas de x colunas # \n",
    "\n",
    "df = df.distinct() # selecionar apenas valores unicos # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = df.createOrReplaceTempView('tabela') # criar uma tabela temporaria a partir de um df # \n",
    "\n",
    "consulta = spark.sql(\"\"\"\n",
    "                        SELECT * FROM database.tabela\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravar DataFrame em formato CSV #\n",
    "df.write.csv(\"saida.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        f.count(('coluna_C').alias('nome_contagem'))\n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        f.countDistinct(('coluna_C').alias('nome'))\n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        f.sum(('coluna_C').alias('nome'))\n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        f.avg(('coluna_C').alias('nome'))\n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        f.min(('coluna_C').alias('nome')), \n",
    "                        f.max(('coluna_D').alias('nome'))\n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna'\n",
    "                ).agg(\n",
    "                        f.collect_list('outra_coluna').alias('lista_distinta') \n",
    "                        # coletar uma lista de valores distintos de uma coluna # \n",
    "                    )\n",
    "\n",
    "x = df.groupBy(\n",
    "                'coluna_A', 'coluna_B'\n",
    "                ).agg(\n",
    "                        (f.col('coluna_C') - f.col('coluna_D')).alias('nome')\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('nova_coluna', f.col('coluna_a') + f.col('coluna_b')) # somar os valores de duas colunas #\n",
    "\n",
    "df = df.withColumnRenamed('nome_alterado', 'nome_original') # alterar o nome da coluna #\n",
    "\n",
    "df = df.withColumn('nova_coluna', f.concat(f.col('coluna_a'), f.lit(' '), f.col('coluna_b')))\n",
    "\n",
    "df = df.withColumn('nova_coluna', f.concat(f.lit(2), f.col('coluna_a'))) # criar valor e adicionar a coluna #\n",
    "\n",
    "df = df.withcolumn('nova_coluna', f.lpad(f.col('coluna_a'), 2, '0')) # inserir um valor a esquerda # \n",
    "\n",
    "df = df.withcolumn('nova_coluna', f.rpad(f.col('coluna_a'), 2, '0')) # inserir um valor a direita # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(\n",
    "    df_2, \n",
    "    on = ['chave_id'],\n",
    "    how = 'inner' # encontrar apenas os valores em comuns dos dois dataframes #\n",
    ")\n",
    "\n",
    "df_join = df.join(\n",
    "    df_2, \n",
    "    on = ['chave_id'],\n",
    "    how = 'full' # adicionar tudo dos dois dataframes #\n",
    ")\n",
    "\n",
    "df_join = df.join(\n",
    "    df_2, \n",
    "    on = ['chave_id'],\n",
    "    how = 'left' # adicionar as informações do dataframe a direita ao da esquerda #\n",
    ")\n",
    "\n",
    "# a diferença entre o join e o union é que o union precisa de dataframes iguais e \n",
    "# o join pode ser com dataframes diferentes com um identificador em comum #\n",
    "\n",
    "df_union = df.union(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "                    'nova coluna', f.when(f.col('coluna_x') > 10, 'maior que 10'\n",
    "                    ).otherwise('menor que 10')\n",
    "                    )\n",
    "\n",
    "df = df.orderBy(f.col('coluna').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(f.col('coluna').isNull()) # filtar apenas os valores nulos de uma coluna #\n",
    "\n",
    "df = df.filter(f.col('coluna').isNotNull()) # filtrar apenas os valores não nulos de uma coluna #\n",
    "\n",
    "df = df.fillna({'coluna': 'valor_padrao'}) # preencher valores nulos em uma coluna # \n",
    "\n",
    "df_not_null = df.dropna(subset=['coluna1', 'coluna2']) # dropar linhas com valores nulos # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulação de datas # \n",
    "import datetime as dt \n",
    "\n",
    "# criando uma data passada # \n",
    "dt_hoje = dt.datetime.now()\n",
    "df = df.withColumn('data_x', f.lit(dt_hoje - dt.timedelta(days=60)))\n",
    "\n",
    "# separando a data # \n",
    "df = df.withColumn('data_date', f.col('data_string_ou_outro').cast('date'))\n",
    "\n",
    "df = df.withColumn(\"ano\", f.year(\"data_date\"))\n",
    "df = df.withColumn(\"mes\", f.month(\"data_date\"))\n",
    "df = df.withColumn(\"dia\", f.day(\"data_date\"))\n",
    "df = df.withColumn(\"semana_ano\", f.weekofyear(\"data_date\"))\n",
    "df = df.withColumn(\"dia_semana\", f.dayofweek(\"data_date\"))\n",
    "\n",
    "# a diferença entre duas datas # \n",
    "df = df.withColumn('diferenca_dias', f.datediff(df_1['data_a'], df_2['data_b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter dados # \n",
    "df = df.withColum('coluna_alterada', f.col('coluna').cast('int')) # inteiro # \n",
    "\n",
    "df = df.withColum('coluna_alterada', f.col('coluna').cast('double')) # float # \n",
    "\n",
    "df = df.withColum('coluna_alterada', f.col('coluna').cast('string')) # 'texto' # \n",
    "\n",
    "df = df.withColumn('coluna_alterada', f.col('coluna').cast('date')) # 'yyyy-MM-dd' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de for # \n",
    "\n",
    "lista_colunas = ['coluna_1', 'coluna_2']\n",
    "\n",
    "mediana = df_clientes_reduzido.groupBy(\n",
    "    \"fl_churn\",\n",
    "    \"fl_plano_internacional\",\n",
    "    \"fl_plano_correio_voz\"\n",
    "    ).agg(\n",
    "        *[f.expr(f\"percentile_approx({col}, 0.5)\").alias(f'mediana_{col}') for col in lista_colunas] # \n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
